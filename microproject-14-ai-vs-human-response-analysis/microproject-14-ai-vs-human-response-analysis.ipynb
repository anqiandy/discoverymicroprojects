{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "<div style=\"color: #DD3403; font-size: 60%\">Data Science DISCOVERY MicroProject</div>\n",
    "<span style=\"\">MicroProject #14: AI vs Human: Response Analysis</span>\n",
    "<div style=\"font-size: 60%;\"><a href=\"https://discovery.cs.illinois.edu/microproject/ai-vs-human-response-analysis/\">https://discovery.cs.illinois.edu/microproject/ai-vs-human-response-analysis/</a></div>\n",
    "</h1>\n",
    "\n",
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source: Hugging Face HC3 Dataset\n",
    "\n",
    "[Hugging Face](https://huggingface.co/) is a company that has developed a platform for natural language processing (NLP) applications. They have created and shared a large collection of pre-trained models, datasets, and learning resources which are open-source and available for the public to use.\n",
    "\n",
    "Hello-SimpleAI is a small group of researchers (PhD students and engineers) that released the [HC3 dataset](https://arxiv.org/abs/2301.07597). This dataset compares human responses (from Reddit, Wikipedia, and other sources) and AI responses to the same question, with details available on their GitHub repository ([@Hello-SimpleAI/chatgpt-comparison-detection](https://github.com/Hello-SimpleAI/chatgpt-comparison-detection)) or via the [Hugging Face API](https://huggingface.co/datasets/Hello-SimpleAI/HC3/viewer/all/train).\n",
    "\n",
    "Are responses from AI different from humans? Let's nerd out with with this data and find out! ðŸŽ‰\n",
    "\n",
    "\n",
    "### Background Knowledge\n",
    "\n",
    "To finish this MicroProject, we assume you already know:\n",
    "\n",
    "- All topics covered in *DISCOVERY Module 1: Basics of Data Science with Python* ([review the module here](https://discovery.cs.illinois.edu/learn/))\n",
    "- Adding new columns into an existing DataFrame ([review creating new columns here](https://discovery.cs.illinois.edu/guides/Modifying-DataFrames/adding-columns-in-dataframes/))\n",
    "- Working with functions in Python ([review Python functions here](https://discovery.cs.illinois.edu/learn/Simulation-and-Distributions/Functions-in-Python/))\n",
    "- Understanding (and performing) hypothesis tests ([review hypothesis testing here](https://discovery.cs.illinois.edu/learn/Polling-Confidence-Intervals-and-Hypothesis-Testing/Hypothesis-Testing/))\n",
    "\n",
    "Let's get started! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading the Dataset\n",
    "\n",
    "For this MicroProject, we have provided the first 100 samples of the `Hello-SampleAI` dataset that was gathered from the following URL: https://datasets-server.huggingface.co/rows?dataset=Hello-SimpleAI%2FHC3&config=all&split=train&offset=0&length=100\n",
    "\n",
    "This data has been **cleaned up and provided to you** as `huggingface-hello-sampleAI-100.csv`.  This dataset has 100 `question`s that were asked and answered on the  \"Explain Like I'm Five\" (ELI5) subreddit, with the `human_answer` from reddit and a `chatgpt_answer` from ChatGPT.\n",
    "\n",
    "Load the cleaned up CSV file dataset as a DataFrame `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>human_answer</th>\n",
       "      <th>chatgpt_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is every book I hear about a \" NY Times # ...</td>\n",
       "      <td>Basically there are many categories of \" Best ...</td>\n",
       "      <td>There are many different best seller lists tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If salt is so bad for cars , why do we use it ...</td>\n",
       "      <td>salt is good for not dying in car crashes and ...</td>\n",
       "      <td>Salt is used on roads to help melt ice and sno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do we still have SD TV channels when HD lo...</td>\n",
       "      <td>The way it works is that old TV stations got a...</td>\n",
       "      <td>There are a few reasons why we still have SD (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has nobody assassinated Kim Jong - un He i...</td>\n",
       "      <td>You ca n't just go around assassinating the le...</td>\n",
       "      <td>It is generally not acceptable or ethical to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How was airplane technology able to advance so...</td>\n",
       "      <td>Wanting to kill the shit out of Germans drives...</td>\n",
       "      <td>After the Wright Brothers made the first power...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>How come the Constitution of the US is relevan...</td>\n",
       "      <td>The Constitution is the highest law of the lan...</td>\n",
       "      <td>The Constitution of the United States is the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Why does Valve have Greenlight would n't it ma...</td>\n",
       "      <td>Now , There are 2 problems with steam , and bo...</td>\n",
       "      <td>Valve, the company that developed the Steam pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>why do people so commonly say SO instead of bo...</td>\n",
       "      <td>SO covers boyfriends , girlfriends , husbands ...</td>\n",
       "      <td>People might use the term \"SO\" instead of \"boy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>How do companies that buy &amp; re - sell other pe...</td>\n",
       "      <td>I get that they are \" bottom feeders \" but to ...</td>\n",
       "      <td>When a company or individual owes money to ano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>What is Heisenberg 's uncertainty principle in...</td>\n",
       "      <td>In the simplest terms , anything we do to try ...</td>\n",
       "      <td>Heisenberg's uncertainty principle is a fundam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   Why is every book I hear about a \" NY Times # ...   \n",
       "1   If salt is so bad for cars , why do we use it ...   \n",
       "2   Why do we still have SD TV channels when HD lo...   \n",
       "3   Why has nobody assassinated Kim Jong - un He i...   \n",
       "4   How was airplane technology able to advance so...   \n",
       "..                                                ...   \n",
       "95  How come the Constitution of the US is relevan...   \n",
       "96  Why does Valve have Greenlight would n't it ma...   \n",
       "97  why do people so commonly say SO instead of bo...   \n",
       "98  How do companies that buy & re - sell other pe...   \n",
       "99  What is Heisenberg 's uncertainty principle in...   \n",
       "\n",
       "                                         human_answer  \\\n",
       "0   Basically there are many categories of \" Best ...   \n",
       "1   salt is good for not dying in car crashes and ...   \n",
       "2   The way it works is that old TV stations got a...   \n",
       "3   You ca n't just go around assassinating the le...   \n",
       "4   Wanting to kill the shit out of Germans drives...   \n",
       "..                                                ...   \n",
       "95  The Constitution is the highest law of the lan...   \n",
       "96  Now , There are 2 problems with steam , and bo...   \n",
       "97  SO covers boyfriends , girlfriends , husbands ...   \n",
       "98  I get that they are \" bottom feeders \" but to ...   \n",
       "99  In the simplest terms , anything we do to try ...   \n",
       "\n",
       "                                       chatgpt_answer  \n",
       "0   There are many different best seller lists tha...  \n",
       "1   Salt is used on roads to help melt ice and sno...  \n",
       "2   There are a few reasons why we still have SD (...  \n",
       "3   It is generally not acceptable or ethical to a...  \n",
       "4   After the Wright Brothers made the first power...  \n",
       "..                                                ...  \n",
       "95  The Constitution of the United States is the s...  \n",
       "96  Valve, the company that developed the Steam pl...  \n",
       "97  People might use the term \"SO\" instead of \"boy...  \n",
       "98  When a company or individual owes money to ano...  \n",
       "99  Heisenberg's uncertainty principle is a fundam...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"huggingface-hello-sampleAI-100.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Sample Outputs\n",
    "\n",
    "Run the following cell to view a random question and the human and AI answers to get a feeling for this data (run it again to view a different random question).\n",
    "- *Note that this text has already been tokenized, an early step in almost all text analysis that breaks a sentence into the small tokens for further processing, and may have extra spaces not naturally seen outside of NLP.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Question ==\n",
      "why do people so commonly say SO instead of boyfriend or girlfriend ? I understand what it means , but it just sounds so formal and impersonal to me . Please explain like I'm five.\n",
      "\n",
      "== Human Answer (reddit response) ==\n",
      "SO covers boyfriends , girlfriends , husbands , wives , casual dating , and does so without being gender or status specific .\n",
      "\n",
      "== AI Answer (ChatGPT) ==\n",
      "People might use the term \"SO\" instead of \"boyfriend\" or \"girlfriend\" because it can be a more casual and informal way of referring to their romantic partner. It can also be a way of not disclosing too much personal information about their relationship to others. \n",
      "For example, if someone is talking to a friend and they don't want to share the details of their relationship with that person, they might use the term \"SO\" to refer to their partner. This allows them to talk about their partner without using specific terms that might reveal more about the nature of their relationship. \n",
      "In general, people use different terms to refer to their romantic partners depending on their personal preferences and the context in which they are speaking. Some people might prefer more formal terms, while others might prefer more casual or informal terms.\n"
     ]
    }
   ],
   "source": [
    "# Run the following cell to view a random question and the Human and AI answers to\n",
    "# get a feeling for this data (run it again to view a different random question).\n",
    "sample = df.sample(n=1)\n",
    "print(\"== Question ==\")\n",
    "print(f\"{sample.question.values[0]}\")\n",
    "print()\n",
    "print(\"== Human Answer (reddit response) ==\")\n",
    "print(f\"{sample.human_answer.values[0]}\")\n",
    "print()\n",
    "print(\"== AI Answer (ChatGPT) ==\")\n",
    "print(f\"{sample.chatgpt_answer.values[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ All Tests Passed! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "### TEST CASE for Part 1: Loading the Dataset\n",
    "# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n",
    "# - If this cell results in a celebration message, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "df = df.replace(r'\\r\\n', '\\n', regex=True)\n",
    "assert(\"df\" in vars()), \"Make sure your data is stored in `df`.\"\n",
    "assert(len(df) == 100), \"Your `df` is not the correct length.\"\n",
    "assert(\"How come I have to pay for Foxtel and get ads , when things like youtube are free because they play ads . Should n't Foxtel be you pay and you do nt get ads , or it should be free and you get ads . Please explain like I'm five.\" in df[\"question\"].values)\n",
    "assert(\"It's important to remember that Japan is a country with a rich and diverse culture, and like any other country, it has a range of cultural practices and expressions. While it is true that Japan has a reputation for being a more traditional and conservative culture, it is also home to a vibrant and creative media industry. \\nThe Japanese media industry is known for producing a wide variety of content, including video games, TV shows, and music, that often incorporates elements of Japanese culture and history. This can include things like traditional Japanese instruments and themes, as well as more modern and unconventional elements. \\nIt's also worth noting that different parts of Japanese culture can have different levels of conservatism. For example, some aspects of Japanese culture, such as traditional family structure or gender roles, may be more conservative, while other parts of Japanese culture, such as the media industry, may be more open to experimentation and innovation. \\nOverall, it's important to remember that Japan is a complex and multifaceted culture, and it's not fair to generalize or stereotype all aspects of Japanese culture based on a few specific examples.\" in df[\"chatgpt_answer\"].values)\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Response Length Analysis\n",
    "\n",
    "This MicroProject attempts to identify features that may be distinctive between a human response and an AI response.  One common critique of current AI systems are that the answers are often excessively long.  Our first hypothesis to investigate is that an AI response may be longer than a human response.\n",
    "\n",
    "To explore this, we will explore the average length of an AI response and see if there's any statistical significance to the difference from the human response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1: Finding the Response Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the analysis of response length, we first need to two new columns in our DataFrame for each of our 100 sample questions.  When working with columns that contain `string` data, we work with the individual strings as data using the following **generic syntax**:\n",
    "\n",
    "> ```py\n",
    "> df[\"column\"].str.STRING_FUNCTION()\n",
    "> ```\n",
    "\n",
    "...where `STRING_FUNCTION()` is any of the [string accessor methods](https://pandas.pydata.org/docs/reference/series.html#api-series-str).\n",
    "\n",
    "Specifically, one string accessor method is:\n",
    "\n",
    "> `[...].str.len()`: Compute the length of each element in the Series/Index.\n",
    "\n",
    "To begin our analysis of the length of each response, add two new columns to the DataFrame:\n",
    "- `human_answer_len`, containing the length (in characters) of the human response\n",
    "- `chatgpt_answer_len`, containing the length (in characters) of the ChatGPT response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>human_answer</th>\n",
       "      <th>chatgpt_answer</th>\n",
       "      <th>human_answer_len</th>\n",
       "      <th>chatgpt_answer_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is every book I hear about a \" NY Times # ...</td>\n",
       "      <td>Basically there are many categories of \" Best ...</td>\n",
       "      <td>There are many different best seller lists tha...</td>\n",
       "      <td>600</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If salt is so bad for cars , why do we use it ...</td>\n",
       "      <td>salt is good for not dying in car crashes and ...</td>\n",
       "      <td>Salt is used on roads to help melt ice and sno...</td>\n",
       "      <td>207</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do we still have SD TV channels when HD lo...</td>\n",
       "      <td>The way it works is that old TV stations got a...</td>\n",
       "      <td>There are a few reasons why we still have SD (...</td>\n",
       "      <td>784</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has nobody assassinated Kim Jong - un He i...</td>\n",
       "      <td>You ca n't just go around assassinating the le...</td>\n",
       "      <td>It is generally not acceptable or ethical to a...</td>\n",
       "      <td>613</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How was airplane technology able to advance so...</td>\n",
       "      <td>Wanting to kill the shit out of Germans drives...</td>\n",
       "      <td>After the Wright Brothers made the first power...</td>\n",
       "      <td>59</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>How come the Constitution of the US is relevan...</td>\n",
       "      <td>The Constitution is the highest law of the lan...</td>\n",
       "      <td>The Constitution of the United States is the s...</td>\n",
       "      <td>368</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Why does Valve have Greenlight would n't it ma...</td>\n",
       "      <td>Now , There are 2 problems with steam , and bo...</td>\n",
       "      <td>Valve, the company that developed the Steam pl...</td>\n",
       "      <td>876</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>why do people so commonly say SO instead of bo...</td>\n",
       "      <td>SO covers boyfriends , girlfriends , husbands ...</td>\n",
       "      <td>People might use the term \"SO\" instead of \"boy...</td>\n",
       "      <td>125</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>How do companies that buy &amp; re - sell other pe...</td>\n",
       "      <td>I get that they are \" bottom feeders \" but to ...</td>\n",
       "      <td>When a company or individual owes money to ano...</td>\n",
       "      <td>202</td>\n",
       "      <td>1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>What is Heisenberg 's uncertainty principle in...</td>\n",
       "      <td>In the simplest terms , anything we do to try ...</td>\n",
       "      <td>Heisenberg's uncertainty principle is a fundam...</td>\n",
       "      <td>363</td>\n",
       "      <td>1438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   Why is every book I hear about a \" NY Times # ...   \n",
       "1   If salt is so bad for cars , why do we use it ...   \n",
       "2   Why do we still have SD TV channels when HD lo...   \n",
       "3   Why has nobody assassinated Kim Jong - un He i...   \n",
       "4   How was airplane technology able to advance so...   \n",
       "..                                                ...   \n",
       "95  How come the Constitution of the US is relevan...   \n",
       "96  Why does Valve have Greenlight would n't it ma...   \n",
       "97  why do people so commonly say SO instead of bo...   \n",
       "98  How do companies that buy & re - sell other pe...   \n",
       "99  What is Heisenberg 's uncertainty principle in...   \n",
       "\n",
       "                                         human_answer  \\\n",
       "0   Basically there are many categories of \" Best ...   \n",
       "1   salt is good for not dying in car crashes and ...   \n",
       "2   The way it works is that old TV stations got a...   \n",
       "3   You ca n't just go around assassinating the le...   \n",
       "4   Wanting to kill the shit out of Germans drives...   \n",
       "..                                                ...   \n",
       "95  The Constitution is the highest law of the lan...   \n",
       "96  Now , There are 2 problems with steam , and bo...   \n",
       "97  SO covers boyfriends , girlfriends , husbands ...   \n",
       "98  I get that they are \" bottom feeders \" but to ...   \n",
       "99  In the simplest terms , anything we do to try ...   \n",
       "\n",
       "                                       chatgpt_answer  human_answer_len  \\\n",
       "0   There are many different best seller lists tha...               600   \n",
       "1   Salt is used on roads to help melt ice and sno...               207   \n",
       "2   There are a few reasons why we still have SD (...               784   \n",
       "3   It is generally not acceptable or ethical to a...               613   \n",
       "4   After the Wright Brothers made the first power...                59   \n",
       "..                                                ...               ...   \n",
       "95  The Constitution of the United States is the s...               368   \n",
       "96  Valve, the company that developed the Steam pl...               876   \n",
       "97  People might use the term \"SO\" instead of \"boy...               125   \n",
       "98  When a company or individual owes money to ano...               202   \n",
       "99  Heisenberg's uncertainty principle is a fundam...               363   \n",
       "\n",
       "    chatgpt_answer_len  \n",
       "0                 1114  \n",
       "1                 1148  \n",
       "2                  789  \n",
       "3                  930  \n",
       "4                 1235  \n",
       "..                 ...  \n",
       "95                1281  \n",
       "96                1034  \n",
       "97                 846  \n",
       "98                1254  \n",
       "99                1438  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"human_answer_len\"] = df[\"human_answer\"].str.len()\n",
    "df[\"chatgpt_answer_len\"] = df[\"chatgpt_answer\"].str.len()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2: Compute the Average Answer Lengths\n",
    "\n",
    "Now that we have the lengths of both responses, save the average length of the responses in the variables `human_avg` and `ai_avg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(729.88)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average response length for a human response:\n",
    "human_avg = df[\"human_answer_len\"].mean()\n",
    "human_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1098.77)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average response length for a ChatGPT response:\n",
    "ai_avg = df[\"chatgpt_answer_len\"].mean()\n",
    "ai_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ All Tests Passed! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "### TEST CASE for Part 2.2: Compute the Average Answer Lengths\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "assert(\"human_avg\" in vars()), \"Your average response length for the human responses has to be stored in the variable `human_avg`.\"\n",
    "assert(\"ai_avg\" in vars()), \"Your average response length for the ai responses has to be stored in the variable `ai_avg`.\"\n",
    "assert('human_answer_len' in df.columns), \"The lengths of human responses should be in a column named `human_answer_len` in `df`.\"\n",
    "assert('chatgpt_answer_len' in df.columns), \"The lengths of ChatGPT responses should be in a column named `chatgpt_answer_len` in `df`.\"\n",
    "assert(876 in df[\"human_answer_len\"].values and 930 in df[\"chatgpt_answer_len\"].values), \"Make sure you're using the correct string accessor method.\"\n",
    "assert((human_avg * 390)/30 == 9488.44), \"`human_avg` was calculated incorrectly.\"\n",
    "assert(((ai_avg * 444)/30) + 86 == 16347.796), \"`ai_avg` was calculated incorrectly.\"\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3: Testing if the Difference in Length is Statistically Significant\n",
    "\n",
    "To determine if the difference between the means is statistically significant, we're going to conduct a t-test. Let's first state our null and alternative hypotheses.\n",
    "\n",
    "> **Null hypothesis**: There is no significant difference between the means of the two response lengths.\n",
    "> \n",
    "> **Alternative hypothesis**: There is a significant difference between the means of the two response lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [`scipy.stats.ttest_ind()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) function to get the t-stat (as `t_stat`) and p-value (as `p_value`).\n",
    "\n",
    "You can find the function documentation here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a t-test:\n",
    "#    Syntax: t_stat, p_value = scipy.stats.ttest_ind( ... )\n",
    "from scipy.stats import ttest_ind\n",
    "t_stat, p_value = ttest_ind(df[\"human_answer_len\"], df[\"chatgpt_answer_len\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-3.2043931944794153)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the t-statistic:\n",
    "t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0015776855917118066)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the p-value:\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4: Choosing Your Conclusion\n",
    "\n",
    "Using the calculated p-value and an alpha level of 0.05, we can determine if there is a significant difference between the two mean values.\n",
    "\n",
    "For each set of comments, un-comment **exactly one line in each set** corresponding to the true statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conclusion: The p-value is less than 0.05 (5%) so there IS a statistically significant difference difference between the means of the response lengths.\n"
     ]
    }
   ],
   "source": [
    "# == Un-comment the correct statement for the p-value: ==\n",
    "conclusion_p_value = \"The p-value is less than 0.05 (5%)\"\n",
    "\n",
    "# == Un-comment the correct statement for the significance: ==\n",
    "conclusion_significance = \"there IS a statistically significant difference\"\n",
    "\n",
    "\n",
    "# == We will print your conclusion ==\n",
    "print(f\"Conclusion: {conclusion_p_value} so {conclusion_significance} difference between the means of the response lengths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ All Tests Passed! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "### TEST CASE for Part 2.4: Response Length Analysis\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "assert(\"t_stat\" in vars()), \"Store your t-statistic in the variable `t_stat`. Check the ttest_ind() documentation or the comment in that code box for the correct syntax.\"\n",
    "assert(\"p_value\" in vars()), \"Store your p-value in the variable `p_value`. Check the ttest_ind() documentation or the comment in that code box for the correct syntax.\"\n",
    "\n",
    "import math\n",
    "assert( math.isclose(t_stat * p_value, -0.005055524973109543) ), \"Check your t_stat and p_value.\"\n",
    "assert( len(conclusion_p_value) * len(conclusion_significance) == 1598 ), \"Your conclusion is incorrect.\"\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Sentiment Analysis\n",
    "\n",
    "A second common critique of current AI systems are the answers are often **more subjective** and **optimistic** than a human.\n",
    "\n",
    "There is a field of Data and Computer Science called \"Natural Language Processing (NLP)\" that involves algorithms to analyze the \"polarity\" and \"subjectivity\" score of a piece of text.  In the next two parts of this MicroPorject, we will explore the polarity and subjectivity of human and AI responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1: Using TextBlob to Find the Polarity Scores\n",
    "\n",
    "TextBlob is a Python library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. \n",
    "\n",
    "Among the many features, TextBlob can calculate a polarity score for any given piece of text.  A \"polarity score\" ranges from -1 to 1, where:\n",
    "- A score of -1 is very negative,\n",
    "- A score of 0 is neutral, and\n",
    "- A score of 1 is very positive.\n",
    "\n",
    "For example, the text *\"You will fail DISCOVERY if you do not take the final exam\"* is a negative statement and has a polarity score of -0.25.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.2: Installing TextBlob\n",
    "\n",
    "To use the TextBlob library, we first need to start installing the library:\n",
    "\n",
    "1. In your terminal, type the following: `python3 -m pip install textblob`\n",
    "\n",
    "    - If this command does not work, try the others `pip install` commands listed [here](https://discovery.cs.illinois.edu/guides/System-Setup/Setup-Your-System/#Step-4-Installing-pandas), replacing `pandas` with `textblob`.\n",
    "\n",
    "2. Once it is installed, import the `TextBlob` library with the following import statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtextblob\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.3: Creating a `polarity` Function\n",
    "\n",
    "To allow us to easily find the \"polarity score\" of hundreds of pieces of text using pandas, we need a function that will take a string `s` as input and return the polarity score.\n",
    "\n",
    "Complete the `polarity` function below, by:\n",
    "- Reading the [TextBlob Tutorial: Quickstart](https://textblob.readthedocs.io/en/dev/quickstart.html), specifically focusing on the \"Sentiment Analysis\" portion of the the tutorial.\n",
    "- Finish the `polarity` so that the function returns the polarity score of the input string `s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(s):\n",
    "  testimonial = TextBlob(s)\n",
    "  return testimonial.sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test your function to make sure it's working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextBlob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# From the documentation, we expect a positive (above zero) polarity:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m polarity(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextblob is amazingly simple to use. What great fun!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m, in \u001b[0;36mpolarity\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpolarity\u001b[39m(s):\n\u001b[0;32m----> 2\u001b[0m   testimonial \u001b[38;5;241m=\u001b[39m TextBlob(s)\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m testimonial\u001b[38;5;241m.\u001b[39msentiment\u001b[38;5;241m.\u001b[39mpolarity\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TextBlob' is not defined"
     ]
    }
   ],
   "source": [
    "# From the documentation, we expect a positive (above zero) polarity:\n",
    "polarity(\"Textblob is amazingly simple to use. What great fun!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A negative statement, we expect a negative (below zero) polarity:\n",
    "polarity(\"You will fail DISCOVERY if you do not take the final exam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A neutral statement, we expect a zero polarity:\n",
    "polarity(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to try your own sentence :)\n",
    "polarity(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.4: Finding the Polarity of Human Answers\n",
    "\n",
    "Once you have defined a custom function, you can use it on every row of data by using:\n",
    "> ```python\n",
    "> df[\"column\"].apply( customFunctionName )\n",
    "> ```\n",
    "\n",
    "Note that `customFunctionName` is **ONLY the function name** and does NOT contain the **function call** (there are no parenthesis after the function name; it's just the name of the function). You are providing ONLY the **name of the function** and the `apply` function will internally **call** the function.\n",
    "\n",
    "Using the syntax above, create a new column named `human_polarity` that finds the polarity of the `human_answer` data using the `.apply` operation on a column of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextBlob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman_polarity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(polarity)\n\u001b[1;32m      2\u001b[0m df\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m, in \u001b[0;36mpolarity\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpolarity\u001b[39m(s):\n\u001b[0;32m----> 2\u001b[0m   testimonial \u001b[38;5;241m=\u001b[39m TextBlob(s)\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m testimonial\u001b[38;5;241m.\u001b[39msentiment\u001b[38;5;241m.\u001b[39mpolarity\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TextBlob' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"human_polarity\"] = df[\"human_answer\"].apply(polarity)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.5: Finding the Polarity of ChatGPT Answers\n",
    "\n",
    "Now, find the polarity of ChatGPT answers and save each polarity in the column `chatgpt_polarity`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"chatgpt_polarity\"] = df[\"chatgpt_answer\"].apply(polarity)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 3: Sentiment Analysis - Polarity\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert('human_polarity' in df.columns), \"You must have add a column named `human_polarity` to your DataFrame.\"\n",
    "assert('chatgpt_polarity' in df.columns), \"You must have add a column named `chatgpt_polarity` to your DataFrame.\"\n",
    "\n",
    "import math\n",
    "assert(math.isclose( df[\"human_polarity\"].mean(), 0.07790771420489018 )), \"The calculation of the `human_polarity` is incorrect.\"\n",
    "assert(math.isclose( df[\"chatgpt_polarity\"].std(), 0.11014935757814867 )), \"The calculation of the `chatgpt_polarity` is incorrect.\"\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Overall Results So Far\n",
    "\n",
    "Run the following cell to see a summary of the results you found so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([\n",
    "  {\"Metric\": \"Response Length (mean):\",  \"Human\": human_avg, \"ChatGPT\": ai_avg, \"p-value\": p_value, \"significant\": (\"Yes (p < 0.05)\" if p_value < 0.05 else \"No\") },\n",
    "  {\"Metric\": \"Polarity (mean):\", \"Human\": df.human_polarity.mean(), \"ChatGPT\": df.chatgpt_polarity.mean(), \"p-value\": \"(not tested)\", \"significant\": \"?\" },\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Sentiment Analysis - Subjectivity\n",
    "\n",
    "TextBlob can also calculate a subjectivity score for any given piece of text.  A \"subjectivity score\" ranges from 0 to 1, where:\n",
    "- A score of 0 is not a subjective statement, and\n",
    "- A score of 1 is very subjective statement\n",
    "\n",
    "Using the same library and design as Part 2, create a function called `subjectivity` that returns the subjectivity score of a given string `s`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity(s):\n",
    "  testimonial = TextBolb(s)\n",
    "  return testimonial.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A highly subjective statement, expecting a score above 0.5:\n",
    "subjectivity(\"The best fruit is a kiwi and everyone else is wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A factual statement, expecting a score near 0:\n",
    "subjectivity(\"Winter is colder than summer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to try your own :)\n",
    "subjectivity(\"Andrew is better than andy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4.1: Finding the Subjectivity of Human and ChatGPT Answers\n",
    "\n",
    "Add two new columns to the DataFrame, `human_subjectivity` and `chatgpt_subjectivity`, that stores the subjectivity of each answer for all of the questions.\n",
    "\n",
    "*You may need to look back to the previous section to review how to use the .apply function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextBolb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman_subjectivity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(subjectivity)\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatgpt_subjectivity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatgpt_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(subjectivity)\n\u001b[1;32m      3\u001b[0m df\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m, in \u001b[0;36msubjectivity\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msubjectivity\u001b[39m(s):\n\u001b[0;32m----> 2\u001b[0m   testimonial \u001b[38;5;241m=\u001b[39m TextBolb(s)\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m testimonial\u001b[38;5;241m.\u001b[39msentiment\u001b[38;5;241m.\u001b[39msubjectivity\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TextBolb' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"human_subjectivity\"] = df[\"human_answer\"].apply(subjectivity)\n",
    "df[\"chatgpt_subjectivity\"] = df[\"chatgpt_answer\"].apply(subjectivity)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 4: Sentiment Analysis - Subjectivity\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "import math\n",
    "assert('human_subjectivity' in df.columns), \"You must have add a column named `human_subjectivity` to your DataFrame.\"\n",
    "assert('chatgpt_subjectivity' in df.columns), \"You must have add a column named `chatgpt_subjectivity` to your DataFrame.\"\n",
    "assert( math.isclose( df[\"human_subjectivity\"].mean(), 0.4507534813188739 ) ), \"Your calculation of `human_subjectivity` is incorrect.\"\n",
    "assert( math.isclose( df[\"chatgpt_subjectivity\"].std(), 0.10025355258208316 ) ), \"Your calculation of `chatgpt_subjectivity` is incorrect.\"\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Overall Results So Far\n",
    "\n",
    "Run the following cell to see a summary of the results you found so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([\n",
    "  {\"Metric\": \"Response Length (mean):\",  \"Human\": human_avg, \"ChatGPT\": ai_avg, \"p-value\": p_value, \"significant\": (\"Yes (p < 0.05)\" if p_value < 0.05 else \"No\") },\n",
    "  {\"Metric\": \"Polarity (mean):\", \"Human\": df.human_polarity.mean(), \"ChatGPT\": df.chatgpt_polarity.mean(), \"p-value\": \"(not tested)\", \"significant\": \"?\" },\n",
    "  {\"Metric\": \"Subjectivity (mean of absolutely values):\", \"Human\": df.human_subjectivity.mean(), \"ChatGPT\": df.chatgpt_subjectivity.mean(), \"p-value\": \"(not tested)\", \"significant\": \"?\" },\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Testing if the Difference in Subjectivity is Statistically Significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine if the difference between the subjectivity is statistically significant, we're going to conduct another t-test. Let's first state our null and alternative hypotheses.\n",
    "\n",
    "> **Null hypothesis**: There is no significant difference between the means of the human and ChatGPT subjectivity.\n",
    "> \n",
    "> **Alternative hypothesis**: There is a significant difference between the means of the human and ChatGPT subjectivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5.1: Preforming the t-test\n",
    "\n",
    "Use the `scipy.stats.ttest_ind` function again to get the t-stat and p-value, storing it as `t_stat_subjectivity` and `p_value_subjectivity` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a t-test:\n",
    "#    Syntax: t_stat_subjectivity, p_value_subjectivity = ttest_ind( ... )\n",
    "t_stat_subjectivity, p_value_subjectivity = ttest_ind(df[\"human_subjectivity\"], df[\"chatgpt_subjectivity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat_subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5.2: Choosing Your Conclusion\n",
    "\n",
    "Using the calculated p-value and an alpha level of 0.05, we can determine if there is a significant difference between the two mean values.\n",
    "\n",
    "For each set of comments, un-comment **exactly one line in each set** corresponding to the true statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conclusion: The p-value is less than 0.05 (5%) so there IS a statistically significant difference difference between the means of the subjectivity scores.\n"
     ]
    }
   ],
   "source": [
    "# == Un-comment the correct statement for the p-value: ==\n",
    "conclusion2_p_value = \"The p-value is less than 0.05 (5%)\"\n",
    "\n",
    "# == Un-comment the correct statement for the significance: ==\n",
    "conclusion2_significance = \"there IS a statistically significant difference\"\n",
    "#conclusion2_significance = \"there is NOT a statistically significant difference\"\n",
    "\n",
    "# == We will print your conclusion ==\n",
    "print(f\"Conclusion: {conclusion2_p_value} so {conclusion2_significance} difference between the means of the subjectivity scores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_stat_subjectivity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp_value\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m())\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m( math\u001b[38;5;241m.\u001b[39misclose(t_stat_subjectivity \u001b[38;5;241m*\u001b[39m p_value_subjectivity, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.031921405408979774\u001b[39m) ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck your t_stat and p_value.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m( \u001b[38;5;28mlen\u001b[39m(conclusion2_p_value) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(conclusion2_significance) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1598\u001b[39m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour conclusion is incorrect.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtada\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m All Tests Passed! \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtada\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 't_stat_subjectivity' is not defined"
     ]
    }
   ],
   "source": [
    "### TEST CASE for Part 5: Testing if the Difference in Subjectivity is Statistically Significant\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "assert(\"t_stat\" in vars())\n",
    "assert(\"p_value\" in vars())\n",
    "\n",
    "import math\n",
    "assert( math.isclose(t_stat_subjectivity * p_value_subjectivity, -0.031921405408979774) ), \"Check your t_stat and p_value.\"\n",
    "assert( len(conclusion2_p_value) * len(conclusion2_significance) == 1598 ), \"Your conclusion is incorrect.\"\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Results\n",
    "\n",
    "Run the following cell to see a summary of the results of all of the metrics (we finished the t-test for polarity for you as well):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([\n",
    "  {\"Metric\": \"Response Length (mean):\",  \"Human\": human_avg, \"ChatGPT\": ai_avg, \"p-value\": p_value, \"significant\": (\"Yes (p < 0.05)\" if p_value < 0.05 else \"No\") },\n",
    "  {\"Metric\": \"Polarity (mean):\", \"Human\": df.human_polarity.mean(), \"ChatGPT\": df.chatgpt_polarity.mean(), \"p-value\": 0.3258256055853501, \"significant\": \"No\" },\n",
    "  {\"Metric\": \"Subjectivity (mean of absolutely values):\", \"Human\": df.human_subjectivity.mean(), \"ChatGPT\": df.chatgpt_subjectivity.mean(), \"p-value\": p_value_subjectivity, \"significant\": (\"Yes (p < 0.05)\" if p_value_subjectivity < 0.05 else \"No\") },\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "You're almost done!  All you need to do is to commit your lab to GitHub and run the GitHub Actions Grader:\n",
    "\n",
    "1.  âš ï¸ **Make certain to save your work.** âš ï¸ To do this, go to **File => Save All**\n",
    "\n",
    "2.  After you have saved, exit this notebook and return to https://discovery.cs.illinois.edu/microproject/ai-vs-human-response-analysis/ and complete the section **\"Commit and Grade Your Notebook\"**.\n",
    "\n",
    "3. If you see a 100% grade result on your GitHub Action, you've completed this MicroProject! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
